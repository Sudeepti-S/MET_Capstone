# The Metropolitan Museum of Art X UVA School of Data Science
# The Art of Data Storytelling 
Capstone Team Members : Sudeepti Surapaneni, Logan Lee, Sana Sayed

# ABSTRACT
Machine learning and computer vision have been applied for image recognition of art objects such as paintings, sculpture images etc. In particular, deep learning methods for image classification in art have been used to improve user en- gagement by providing access to accurately labelled and classified art objects. As an increasing number of notable museums turn towards creating open access collections, alternatives to the use of laborious human annotating methods are needed. This paper focuses on the Open Access initiative of The Metropolitan Mu- seum of Art (The Met) which was launched in 2017 in an effort to expand The Met’s reach and presence. The museum now provides a select dataset of information on more than 470,000 artworks in its collection for unrestricted commercial and noncommercial use. However, with a widely accessible collection, the Met now faces the problem of how to enhance the user experience via access to accurately labelled art. This paper focuses on machine learning methods with applicability to automated classification of images obtained from The Met’s online collection. We aimed to: 1) Compare three different convolutional neural networks - ResNet 50, ResNet 101, and Inception-ResNet-V2- using human annotated data, 2) Add transparency and interpretability to our models by using Gradient Weighted Class Activation Maps (GRAD-cams) and to explore bias in gender labels and 3) implement a multi-label classification model using ResNet 50. Future work would include the use of unsupervised clustering methods / auto-encoders to explore additional themes in the data. Other extensions of this work would include exploring methods to implement fine grained visual categorization, to mitigate bias, and to address the limitations associated with culture and stylistic interpretations. Deep learning techniques for art image classification may also help detect consistent features of bias in human annotated art.

# DATA 
As outlined in the data pipeline below, we extracted 469,301 high-resolution images in addition to all the related object metadata from The Met’s API. Each object’s metadata was stored as a JSON string consisting of detailed information such as object ID, origin, tag, and other pieces of artist information, in addition to its corresponding image URL link and 40 other features. We stored the metadata within a SQLite database which was easily integrated with Python. The web- scraped images were stored on Rivanna which is the high- performance computing cluster at UVA. 
